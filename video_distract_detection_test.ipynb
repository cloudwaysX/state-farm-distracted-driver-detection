{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio \n",
    "filename = 'data/testvideo_eating1.mp4'\n",
    "vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "\n",
    "i  = 0\n",
    "for image in vid.iter_data():\n",
    "    i+=1\n",
    "    if i%10 == 0: imageio.imwrite('frames/{}.jpg'.format(i),image)\n",
    "        \n",
    "# import imageio\n",
    "# import visvis as vv\n",
    "\n",
    "# reader = imageio.get_reader('<video0>')\n",
    "# t = vv.imshow(reader.get_next_data(), clim=(0, 255))\n",
    "# for im in reader:\n",
    "#     vv.processEvents()\n",
    "#     t.SetData(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "from src.extractor_utils import (predict, save_prediction)\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "from src.imgnet_utils import denormalize\n",
    "from src.data_loader import _create_dataLoader\n",
    "from src.data_loader import _create_dataLoader\n",
    "from src.convnet_models import (MyResNet, MyInception, MyDenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import  Dataset, TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "from src.imgnet_utils import denormalize\n",
    "\n",
    "from src.data_loader import _create_dataLoader\n",
    "\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "\n",
    "from src.plot_utils import (plot_classes, plot_distribution,\n",
    "                            statistical_analysis_image, classDistribution,\n",
    "                            plot_metrics,visualize_predictions,\n",
    "                            plot_cm_train_valid,plot_layers_weight)\n",
    "      \n",
    "from src.convnet_models import (MyResNet, MyInception, MyDenseNet)\n",
    "from src.extractor_utils import (predict, getPrediction,save_prediction,\n",
    "                                 load_prediction, torch_summarize,RandomSearch)\n",
    "\n",
    "from utils.utils import (create_submission ,metrics2csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing resources to extrac the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU's available:\n",
      "\n",
      "cpu_count: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"{} GPU's available:\".format(torch.cuda.device_count()) )\n",
    "cpu_count = torch.multiprocessing.cpu_count()\n",
    "print(\"\\ncpu_count: {}\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only one GPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "use_DataParalel= False\n",
    "use_CPU= False        \n",
    "\n",
    "if use_gpu:\n",
    "    if use_DataParalel: \n",
    "        print(\"Using DataParalel in all {} GPUS\".format(torch.cuda.device_count()))\n",
    "\n",
    "    else:\n",
    "        print('Using only one GPU')\n",
    "\n",
    "if use_CPU:         # http://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html \n",
    "    print(\"Using {} CPU's\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2test = \"frames\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifang/anaconda3/envs/python3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py:176: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    }
   ],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "img_width = img_height=300 #to use InceptionV3 it must img_width and img_height be changed to 300\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "use_only = 1.0 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'test':  KaggleSafeDriverDataset(path2test, transforms=data_transforms['test'],use_only=use_only, is_test=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = _create_dataLoader(dsets, batch_size, pin_memory=False, use_shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, {'test': 74})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes = {x: len(dsets[x]) for x in ['test']} \n",
    "dset_classes = len(dsets['test'].y)\n",
    "dset_classes, dset_sizes\n",
    "\n",
    "# Dataset have much more samples than datatrain ***It comes from the test.zip****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DenseNet model\n"
     ]
    }
   ],
   "source": [
    "use_resnet = False\n",
    "use_inception = False\n",
    "use_denseNet = True\n",
    "\n",
    "if use_resnet:\n",
    "    print('Using ResNet model')\n",
    "    model_name = \"ResNet\"\n",
    "    model = MyResNet()\n",
    "elif use_inception:\n",
    "    print('Using Inception model')\n",
    "    model_name = \"Inception\"\n",
    "    model = MyInception()\n",
    "elif use_denseNet:\n",
    "    print('Using DenseNet model')\n",
    "    model_name = \"DenseNet\"    \n",
    "    model = MyDenseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    print('Using GPU')# {}'.format(device_id))\n",
    "    model.cuda()\n",
    "    convnet = model.mrnc \n",
    "\n",
    "if use_CPU:\n",
    "    print(\"Using CPU's\")\n",
    "    convnet = model.mrnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "predict: 0/2\r",
      "predict: 1/2\r",
      "predict: 2/2 ok\n",
      "Execution time 1.00 s\n",
      "torch.Size([74]) torch.Size([74, 2208])\n"
     ]
    }
   ],
   "source": [
    "#extract features from images\n",
    "convOutput_test = predict(dset_loaders['test'], convnet,use_gpu=use_gpu)\n",
    "print(convOutput_test['true'].size(), convOutput_test['pred'].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "predict: 0/2\r",
      "predict: 1/2\r",
      "predict: 2/2 ok\n",
      "Execution time 0.00 s\n",
      "\n",
      "Saving DenseNet test\n",
      "Saved in:./results/test/DenseNet.npz\n"
     ]
    }
   ],
   "source": [
    "conv_dset= {\n",
    "    'test':  TensorDataset(convOutput_test['pred'], convOutput_test['true'])\n",
    "}\n",
    "dset_loaders_convnet = _create_dataLoader(conv_dset, batch_size, \n",
    "                        pin_memory=False, use_shuffle= True)\n",
    "\n",
    "\n",
    "\n",
    "# num_epochs = 50\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer =  optim.Adam(model.mrnd.parameters(), lr=1e-3,weight_decay=0)\n",
    "\n",
    "# params = {'model' : model.mrnd, \n",
    "#     'criterion': loss_fn,  \n",
    "#     'optimizer': optimizer, \n",
    "#     'callbacks': [savebest, ptt.AccuracyMetric()] #ptt.PlotCallback(),\n",
    "# }\n",
    "# params['callbacks'].append(ptt.PrintCallback())\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.55)\n",
    "# trainer = ptt.DeepNetTrainer(use_gpu=use_gpu,lr_scheduler=scheduler,**params)\n",
    "path2saveModel = './models/'+model_name+'RandomSearch'+'DistractDriver' \n",
    "model.mrnd.load_state_dict(torch.load(path2saveModel + '.model', map_location=lambda storage, loc: storage))\n",
    "# make a prediction\n",
    "result_test = predict(dset_loaders_convnet['test'], model.mrnd, use_gpu=use_gpu)\n",
    "predictions_out = {'test': (result_test['pred'], result_test['true'], model_name)}\n",
    "# save prediction\n",
    "path2results = './results/'\n",
    "save_prediction(path2results,predictions_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 7 \n",
       " -1.9912   2.5178   2.2675   3.2014   0.4789  -3.4275   7.7902  -6.8293\n",
       " -3.7951   1.8742  -5.3601   2.3707  -2.1447   4.2876   1.2077  -1.4793\n",
       "  3.6310   7.6535  -4.8039  -3.7464  -5.1389   5.6956  -5.4594  -0.0135\n",
       " -0.0664   3.6334  -4.4866  -0.6831  -5.4756  -0.3897   0.2998  -0.3111\n",
       "  1.4952  -2.9310  -2.6234   0.0652   2.2749   2.6195   0.0176  -1.3132\n",
       " -6.9206  -8.3026  -2.1276  -2.0370   4.6868   0.2801   4.8130  -1.1631\n",
       " -1.5386   1.7804  -3.3565   0.1527  -4.0420   3.2964   0.5270  -1.6409\n",
       " -1.9597   0.1089  -4.0956   2.7950  -3.7383   1.8269  -1.1254   3.3506\n",
       " -6.6974  -1.2856   4.8005   3.7027   2.1396  -4.3035   8.2384  -6.0202\n",
       "  1.6423  -1.7525  -2.8793  -4.8347  -0.2570   2.6072  -4.0379  -1.0506\n",
       " -1.0892   4.0253  -2.5844  -3.6867  -5.3451   0.3265  -3.0611  -0.4431\n",
       "  0.3043  -2.4144  -0.5293  -0.9771  -3.1491   5.2794   0.7433  -0.9931\n",
       "  3.8289  -2.2835  -1.6925  -3.2535   0.5250   5.0542  -4.7588  -1.5687\n",
       " -2.3960   5.5308  -1.0720   6.9864  -1.2374  -2.1085  -0.1973  -3.3090\n",
       " -3.0302   1.3731  -2.4389  -5.9136   0.8032   0.3337   0.6130  -0.9908\n",
       " -8.4118  -2.3570  -4.7211  11.8337   2.2475  -1.2175   6.2643  -3.4203\n",
       " -2.1242   5.8808  -1.3002   1.0377  -4.8752   6.3660  -2.7024  -0.2010\n",
       " -4.5612  -2.5680  -1.4384  -5.4233  -3.6909   8.9681   5.1245  -1.1609\n",
       " -3.3111   6.5139   0.2737   2.9778  -0.9547  -3.9868   6.9507  -3.6354\n",
       "  3.6831  -3.3033  -7.9332  -4.5569  -2.8402   1.7594  -7.1323   0.3438\n",
       " -3.2714   3.6183  -3.7700  -0.1763   0.5635   0.8929   1.5282  -1.6097\n",
       " -5.7743   1.6089  -2.1864   5.1665   1.3645  -0.4609   4.7239  -3.5793\n",
       "  0.6219   1.1052  -4.7255  -1.0454  -3.2830  -1.9379  -1.3564  -1.6888\n",
       " -6.9982   6.5963   4.1591  -3.5776  -6.6868  -1.9006   0.9213   2.3185\n",
       " -1.5795  -2.3430  -6.2004   8.4175   3.6450   0.1697  -1.4008  -4.8058\n",
       "  1.8063  -3.6652  -6.4910  -3.6078   2.2903   5.6102  -5.7344  -1.0489\n",
       " -2.6338   1.9270  -0.0924  -4.7647  -0.4211  -1.7254  -2.3574   3.7899\n",
       " -2.8376  -5.4068   1.4415  -4.8768   3.6821   1.3894   0.7187  -4.3777\n",
       " -4.6679  -3.8573  14.4741  -5.3713   3.1299  -7.7344   4.5607  -2.3557\n",
       " -2.8093  -1.2746   7.8210   0.3542  -0.8191  -6.8770   3.8162  -3.2486\n",
       " -2.6374  -2.8023  -1.5439  -3.2091   0.7652  -0.9171  -4.9956   2.7595\n",
       " -0.4050  -3.2927   6.9782  -0.2677   0.2486  -7.5747   6.0386  -3.3615\n",
       " -5.1201  -6.4125   0.4951   3.3539   7.6523  -3.7028   5.9412  -3.1633\n",
       "  1.3265   4.1875  -4.9904   0.8836  -3.9353   7.5420  -4.2363   0.3738\n",
       "  5.0069   3.0960  -3.3883  -3.6181  -5.2932   6.3559  -2.3373  -4.3912\n",
       "  0.6400  -5.6872  -7.3490  -1.3042   0.3201   2.8459  -1.6818  -3.6638\n",
       "  2.8750   2.3774  -6.4242   0.8260  -5.5241  10.5260  -6.4275  -0.0267\n",
       " -0.8701  -3.1307   0.6733  -0.3624   3.5504   2.2217  -0.5812  -2.2946\n",
       "  3.5823   4.7938  -5.7294  -1.3186  -5.2126   2.9003  -6.8407   1.6193\n",
       "  0.4903  -4.7530  -5.0356   0.6474  -0.4480   5.5156  -3.7954  -2.3081\n",
       "  2.2965  -2.0815  -6.4202   2.7713   1.8251  -1.4423  -0.5181  -5.1731\n",
       "  2.5815  12.5536  -1.9095  -1.8691  -8.2454  -0.9763  -0.0889  -2.9293\n",
       " -0.4843  -2.0406  -4.2059  -2.8519  -2.2578   6.3939  -2.6099  -0.5886\n",
       "  0.3417  -1.2333  -2.4660   6.0815   0.2079  -0.5797   0.3494  -3.9693\n",
       " -2.5823  -0.4924   4.9544   1.8854   1.3649   1.4479  -0.3430  -4.3717\n",
       " -0.7015  -4.8986  13.1676  -1.5389  -1.1938  -6.5754   3.7921  -4.3195\n",
       " -7.9745   1.9673  -2.2082  -6.0374  -0.5741  -3.1451   6.9055   6.3706\n",
       " -5.4029  -1.4848  -0.4968   4.7575   1.4258   2.2837   5.4920  -3.9325\n",
       "  1.1957   6.0877  -2.2729  -2.8720  -3.5441   1.1674  -1.4708  -0.5701\n",
       " -1.4829  10.3168  -2.0835  -3.1895  -4.6414  -2.0454  -1.9105  -0.0397\n",
       "  4.0170   3.2672  -2.6173  -5.2794  -6.8125   3.0762  -1.6371  -1.0794\n",
       "  4.2355   1.3946  -8.7938  -2.4519  -5.6490   2.4823  -7.0539   0.1455\n",
       " -2.9850  -0.2999   7.6957  -6.9633  -1.0139   4.9514  -1.8339  -4.2761\n",
       " -2.2458  -6.8101   4.3437   0.3693   1.8386   1.3698   4.1688  -6.0468\n",
       "  1.9945   3.1974  -4.3477  -0.9253  -3.1340  -0.5774  -1.8496  -2.8412\n",
       " -2.1318  -2.0315  -1.6195   3.4918   3.5618   1.2898   4.2805  -5.2632\n",
       "  2.6602   5.6389  -3.1234   4.8092  -2.3719   3.1469   1.2825  -2.4519\n",
       " -4.3477   1.5339  10.8040  -0.7888  -3.1417  -9.4568   6.1472  -5.6943\n",
       " -3.1215   0.4230  -0.9928   2.3412   0.8209   2.6232   3.8027  -2.7895\n",
       " -2.0522   6.1269   0.6598   3.9604  -2.9914  -6.8180   1.3370  -4.2611\n",
       " -4.3668  -6.2394  -6.5580   0.7362  -2.7880  16.0433  -0.5443   3.1732\n",
       " -4.1915  -7.9858   0.1660   0.8791   8.0336  -3.6515   2.9419  -2.4641\n",
       " -4.5103   4.4813   6.3185  -5.5640  -0.1465  -4.2621  -1.2156  -1.7390\n",
       "  0.4682  -2.4526  -4.3691  -0.9269   2.9910   4.4629  -3.5641  -3.1186\n",
       " -0.5753  -3.8305  -6.3796  -3.9316  -1.7242  11.7944  -2.2857   2.1858\n",
       "\n",
       "Columns 8 to 9 \n",
       "  3.1271  -5.1164\n",
       "  3.4828  -1.7339\n",
       "  1.8335  -1.3317\n",
       "  1.6316   2.5624\n",
       " -0.3489   0.8962\n",
       " 10.1996   1.6821\n",
       "  4.0640   0.1286\n",
       "  4.0424  -3.2122\n",
       "  3.5035  -3.7443\n",
       " -0.7724   7.6723\n",
       "  2.5801   5.6883\n",
       " -0.5056   3.2530\n",
       "  1.7138   0.7960\n",
       " -0.1107  -2.1809\n",
       "  7.9316  -0.0512\n",
       "  2.8657  -5.0922\n",
       " -1.9243  -1.3127\n",
       "  3.3812   1.6593\n",
       "  0.3202  -4.3784\n",
       "  2.6344   8.6863\n",
       "  2.7774  -3.1762\n",
       "  4.4989  -5.1004\n",
       "  3.2120   4.1108\n",
       "  5.4605  -2.0337\n",
       "  2.7614  -2.4187\n",
       " -0.0280   5.5669\n",
       "  1.6134   2.4237\n",
       "  4.1394   2.1102\n",
       "  5.7351  -4.9403\n",
       "  6.6663  -1.9785\n",
       "  5.5054   2.6562\n",
       "  7.2393  -4.3205\n",
       "  6.9130  -4.6507\n",
       " -2.3191  -0.1435\n",
       " -1.8623   1.3733\n",
       "  5.5608   4.3894\n",
       " -0.2986  -1.3192\n",
       "  2.8253  -1.8848\n",
       " -0.6548   1.9061\n",
       " -2.9429   5.9410\n",
       "  6.4677   1.4274\n",
       " -1.3741  -1.1855\n",
       "  0.5041   5.1258\n",
       "  2.2081  -1.2717\n",
       "  1.5946  -2.9320\n",
       "  7.8594  -4.0429\n",
       "  8.9340  -2.5950\n",
       "  1.9678  -4.9279\n",
       "  1.0556   0.4546\n",
       "  1.9655  -1.0446\n",
       "  1.2730   0.0268\n",
       "  4.3827   3.8251\n",
       "  2.1279  -0.2286\n",
       "  4.6957  -1.1160\n",
       "  0.8035   4.3696\n",
       "  3.2569  -2.8052\n",
       " -3.4355  -5.7732\n",
       "  6.3466  -4.4270\n",
       "  2.2004  -3.8547\n",
       "  3.2355   0.9499\n",
       "  1.0364  -1.6995\n",
       "  9.6842  -4.5427\n",
       "  6.6341  -1.8506\n",
       "  3.9344   0.4024\n",
       "  0.8125   1.6810\n",
       "[torch.cuda.FloatTensor of size 65x10 (GPU 0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_out['test'][0][9:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred': array([1, 9, 3, 5, 8, 5, 5, 1, 2, 6, 5, 1, 1, 5, 8, 8, 8, 6, 9, 9, 5, 5,\n",
       "        3, 8, 3, 5, 5, 6, 9, 1, 3, 9, 1, 3, 5, 7, 8, 2, 2, 8, 8, 4, 5, 5,\n",
       "        8, 5, 4, 1, 9, 8, 1, 5, 3, 2, 2, 8, 6, 1, 1, 0, 8, 2, 8, 9, 6, 1,\n",
       "        2, 6, 1, 5, 8, 8, 5, 5]),\n",
       " 'true': array([150, 490, 390, 320, 100, 180, 610, 570, 690, 580, 360, 130, 220,\n",
       "        650, 530, 310, 380, 260, 480, 500, 660,  40, 230,  10, 300, 240,\n",
       "        520, 370, 410, 400, 290, 190,  60, 420, 460,  70,  30, 700, 710,\n",
       "         80, 740, 270, 340, 140, 470, 350, 620, 540, 550, 430, 110, 560,\n",
       "        630, 600, 730,  50, 250, 120,  90, 160, 200, 170, 590, 510, 280,\n",
       "        330, 720, 640, 680, 670, 440,  20, 450, 210])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPrediction(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
